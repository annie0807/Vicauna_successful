{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f9f704-ae5a-4cf4-98d9-c3be31c74f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib\n",
    "import json\n",
    "import contextlib, unicodedata, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "from bs4 import B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c74818-7b68-4d1f-a66a-6f61a7473b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f20b1e2-a923-4cf7-b4dc-d0724de2e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b51a88f-44f3-4bb8-8f2f-4869fa42c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp/raw_text\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Downloads/gcp_tmp/raw_text\n",
    "clusters = []\n",
    "with open(\"title_page_whole_test.txt\", \"r\") as fread:\n",
    "    for line in fread.readlines():\n",
    "        clusters.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b71fab-e22b-4bc3-ba17-46a9301d7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'event_time', 'title_update_time', 'event_link', 'title_update_link', 'update_bs4', 'title_non_update_link', 'title_non_update_time', 'non_update_bs4', 'article_title', 'source_news_first', 'source_news_full', 'article_record', 'update_all_paragraph_with_references', 'update_first_paragraph', 'update_all_paragraph', 'non_update_all_paragraph_with_references', 'non_update_all_paragraph', 'non_update_first_paragraph', 'update_wiki_summary', 'non_update_wiki_summary', 'wiki_portal_summary', 'citation_position', 'event_wcep_id'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0].keys()\n",
    "# title_non_update_link\n",
    "# title_update_link\n",
    "# update_bs4\n",
    "# non_update_bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821ed47-256e-4b82-b46d-47e0fd79b941",
   "metadata": {},
   "source": [
    "### Get the indices of required instances\n",
    "* Keeep English language, with non-updated full-content existed, and meaningful updated full-content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99b7f5f-256f-469c-851d-2ae8486682f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 232)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create idx list\n",
    "all_idx = [i for i in range(len(clusters))]\n",
    "rmved_idx = []\n",
    "\n",
    "for idx in range(len(clusters)):\n",
    "    try:\n",
    "        if bool(len(clusters[idx]['non_update_all_paragraph'].split('. ')) == 1):\n",
    "            rmved_idx.append(idx)\n",
    "    except:\n",
    "        error_idx.append(idx)\n",
    "idx_list = Diff(all_idx, rmved_idx)\n",
    "len(all_idx), len(idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1939a2d5-7574-4f8d-a5f2-5aae48ff246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 226)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmved_idx = []\n",
    "for idx in idx_list:\n",
    "    if len(clusters[idx]['update_first_paragraph'].split())<=10:\n",
    "        rmved_idx.append(idx)\n",
    "id_list = Diff(idx_list, rmved_idx)\n",
    "len(idx_list), len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae3467a-a01a-4a7a-9c95-83c9749368fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 201)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by language of summ==English\n",
    "en_ids = []\n",
    "for idx in id_list:\n",
    "    if isEnglish(clusters[idx]['wiki_portal_summary']):\n",
    "        en_ids.append(idx)\n",
    "len(id_list), len(en_ids)\n",
    "# after filtering, we have 201 instances in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3badb8e-3790-4ecb-a074-799bd959e24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 6]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bdf0fa-1c5f-4812-aeab-0d0ddcc669e7",
   "metadata": {},
   "source": [
    "### Parse the unicode into text\n",
    "* Parse the unicode into text\n",
    "* Paragraphs are separate with `. \\\\c\\\\c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1f89c23-5525-4ccb-a954-ad2e0cdebd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "with open(\"test_text.txt.src\", \"w\") as f:\n",
    "    for idx in en_ids:\n",
    "        bef_rec = []\n",
    "        non_update_all_paragraph = clusters[idx]['non_update_all_paragraph'].split('\\n')\n",
    "        bef_rec.extend(non_update_all_paragraph)\n",
    "        s = '.\\c'\n",
    "        bef_rec_str = s.join(bef_rec).replace(\"\\\\\\\\\\c\", \"\\c\\c\")\n",
    "        with contextlib.redirect_stdout(fwrite):\n",
    "            print({unicodedata.normalize('NFKD', bef_rec_str).encode('utf-8', 'ignore').decode('utf-8')})\n",
    "with open(\"test_text.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        log.append(line.strip().replace(\".\\\\\\\\c\", \"\\c\\c\").replace(\"\\\\\\'s\", \"'s\").replace(\"{\\'\", \"\").replace(\"\\'}\", \"\").replace(\".\\\\c\\\\c\", \". \\\\c\\\\c\"))\n",
    "with open(\"test_text.txt.src\", \"w\") as f:\n",
    "    for line in log:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd382e9d-1043-438a-82b5-3ab5db34e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "with open(\"test_text.txt.tgt\", \"w\") as f:\n",
    "    for idx in en_ids:\n",
    "        tgt_rec = []\n",
    "        update_all_paragraph = clusters[idx][\"update_all_paragraph\"].split(\"\\n\")\n",
    "        tgt_rec.extend(update_all_paragraph)\n",
    "        s = \".\\c\"\n",
    "        tgt_rec_str = s.join(tgt_rec).replace(\"\\\\\\\\\\c\", \"\\c\\c\")\n",
    "        with contextlib.redirect_stdout(f):\n",
    "            print({unicodedata.normalize('NFKD', bef_rec_str).encode('utf-8', 'ignore').decode('utf-8')})\n",
    "with open(\"test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        log.append(line.strip().replace(\".\\\\\\\\c\", \"\\c\\c\").replace(\"\\\\\\'s\", \"'s\").replace(\"{\\'\", \"\").replace(\"\\'}\", \"\").replace(\".\\\\c\\\\c\", \". \\\\c\\\\c\"))\n",
    "with open(\"test_text.txt.tgt\", \"w\") as f:\n",
    "    for line in log:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180b606-e927-476d-9da0-7784458e0814",
   "metadata": {},
   "source": [
    "### Extract the section name for each paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a5b07cf-5c78-4809-b864-b1a09dcecc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clusters[0][\"non_update_bs4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c884fc1e-4c12-4282-8b73-44a132e75a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Bidding process',\n",
       "  'Host city selection',\n",
       "  'Impact of the COVID-19 pandemic',\n",
       "  'Qualifying event cancellation and postponement',\n",
       "  'Effect on doping tests',\n",
       "  'Postponement to 2021',\n",
       "  'Calls for cancellation',\n",
       "  'Costs and insurance',\n",
       "  'Development and preparation',\n",
       "  'Venues and infrastructure',\n",
       "  'Security',\n",
       "  'Volunteers',\n",
       "  'Medals',\n",
       "  'Torch relay',\n",
       "  'Biosecurity protocols',\n",
       "  'Ticketing',\n",
       "  'Cultural festival',\n",
       "  'The Games',\n",
       "  'Opening ceremony',\n",
       "  'Sports',\n",
       "  'Test events',\n",
       "  'Participating national Olympic committee teams',\n",
       "  'Number of athletes by National Olympic Committee',\n",
       "  'Medal summary',\n",
       "  'Podium sweeps',\n",
       "  'Calendar',\n",
       "  'Event scheduling',\n",
       "  'Marketing',\n",
       "  'Victory ceremonies',\n",
       "  'Colors',\n",
       "  'Concerns and controversies',\n",
       "  'Related to the Organizing Committee',\n",
       "  'Broadcasting'],\n",
       " 33)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# section names except (\"See also\", \"References\")\n",
    "text = clusters[0][\"non_update_bs4\"]\n",
    "end_idx = re.findall('<span class=\"toctext\">(.*)</span>', text).index('See also')\n",
    "sec_names = re.findall('<span class=\"toctext\">(.*)</span>', text)[:end_idx]\n",
    "sec_names, len(sec_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e2fe6351-c185-4c7c-910f-6bec1c008ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bidding process': 1,\n",
       " 'Host city selection': 1,\n",
       " 'Impact of the COVID-19 pandemic': 2,\n",
       " 'Qualifying event cancellation and postponement': 1,\n",
       " 'Effect on doping tests': 1,\n",
       " 'Postponement to 2021': 3,\n",
       " 'Calls for cancellation': 8,\n",
       " 'Costs and insurance': 3,\n",
       " 'Development and preparation': 5,\n",
       " 'Venues and infrastructure': 4,\n",
       " 'Security': 1,\n",
       " 'Volunteers': 2,\n",
       " 'Medals': 4,\n",
       " 'Torch relay': 4,\n",
       " 'Biosecurity protocols': 7,\n",
       " 'Ticketing': 3,\n",
       " 'Cultural festival': 2,\n",
       " 'Opening ceremony': 1,\n",
       " 'Sports': 8,\n",
       " 'Test events': 3,\n",
       " 'Participating national Olympic committee teams': 7,\n",
       " 'Number of athletes by National Olympic Committee': 2,\n",
       " 'Medal summary': 1,\n",
       " 'Podium sweeps': 1,\n",
       " 'Calendar': 3,\n",
       " 'Event scheduling': 1,\n",
       " 'Marketing': 2,\n",
       " 'Victory ceremonies': 1,\n",
       " 'Colors': 1,\n",
       " 'Concerns and controversies': 11,\n",
       " 'Related to the Organizing Committee': 8,\n",
       " 'Broadcasting': 4}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the numbers of paragraphs from each section\n",
    "# section start from index 1, names start from index 0\n",
    "'''\n",
    "# clusters[0][\"non_update_bs4\"].split('<span class=\"mw-headline')[1].split(\"<p>\")[1:]\n",
    "# len(clusters[0][\"non_update_bs4\"].split('<span class=\"mw-headline'))-1\n",
    "'''\n",
    "'''\n",
    "# num_pars = []\n",
    "# for idx in range(len(sec_names)):\n",
    "#     num_par = len(clusters[0][\"non_update_bs4\"].split('<span class=\"mw-headline')[idx+1].split(\"<p>\")[1:])\n",
    "#     num_pars.append(num_par)\n",
    "# num_pars, len(num_pars)\n",
    "'''\n",
    "num_pars = [len(clusters[0][\"non_update_bs4\"].split('<span class=\"mw-headline')[i+1].split(\"<p>\")[1:]) for i in range(len(sec_names))]\n",
    "secs_pars = dict(zip(sec_names, num_pars))\n",
    "# remove the section with no paragraphs (this problem ocurrs when the main section do not involved summary but only sub-sections)\n",
    "secs_pars_nums = {k: v for k, v in secs_pars.items() if v!=0}\n",
    "secs_pars_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89036952-3f0c-4d2b-b12b-4b7e6c48838b",
   "metadata": {},
   "source": [
    "* Since full-article includes \"summary\", we have to remove the \"summary\" before alignment -> then add back to the text afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ed5c2adc-907a-4f64-9056-8682ab1b784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "# summary = clusters[2][\"non_update_wiki_summary\"]\n",
    "contents_with_summ = []\n",
    "with open(\"test_text.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        contents_with_summ.append(line)\n",
    "\n",
    "for idx in range(len(en_ids)):\n",
    "    real_id = en_ids[idx]\n",
    "    s = \"\\\\c\\\\c\"\n",
    "    summs = clusters[real_id][\"non_update_wiki_summary\"].split(\"\\n\") # splitted summary\n",
    "    full_content_with_summ = contents_with_summ[idx]\n",
    "    with_summs = full_content_with_summ.split(\"\\\\c\\\\c\") # splitted contents with summ\n",
    "    for par in with_summs:\n",
    "        if par in summs: with_summs.remove(par) \n",
    "with open(\"test_no_summs.txt.src\", \"w\") as f:\n",
    "    for line in with_summs: f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "07639809-303f-4fbe-9506-5d369b31db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_summs = []\n",
    "with open(\"test_no_summs.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines(): no_summs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a94717c2-41a7-4313-bdef-5f646b18f15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In March and April 2021, Russia started to mass thousands of military personnel and equipment near its border with Ukraine, representing the highest force mobilization since the country's annexation of Crimea in 2014. This precipitated an international crisis and generated concerns over a potential invasion. Satellite imagery showed movements of armor, missiles, and heavy weaponry. The troops were partially removed by June. The crisis was renewed in October and November 2021, when over 100,000 Russian troops were again massed near the border by December. \\n\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_summs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9e412-1582-4263-9b02-b136ce76d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_with_summ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f391c07-faa0-4210-9c7f-ea2d303f409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-venv",
   "language": "python",
   "name": "data-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
