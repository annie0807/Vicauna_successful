{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f9f704-ae5a-4cf4-98d9-c3be31c74f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib\n",
    "import json\n",
    "import contextlib, unicodedata, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "from bs4 import B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67c74818-7b68-4d1f-a66a-6f61a7473b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f20b1e2-a923-4cf7-b4dc-d0724de2e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b51a88f-44f3-4bb8-8f2f-4869fa42c2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp/raw_text\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Downloads/gcp_tmp/raw_text\n",
    "clusters = []\n",
    "with open(\"title_page_whole_test.txt\", \"r\") as fread:\n",
    "    for line in fread.readlines():\n",
    "        clusters.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b71fab-e22b-4bc3-ba17-46a9301d7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'event_time', 'title_update_time', 'event_link', 'title_update_link', 'update_bs4', 'title_non_update_link', 'title_non_update_time', 'non_update_bs4', 'article_title', 'source_news_first', 'source_news_full', 'article_record', 'update_all_paragraph_with_references', 'update_first_paragraph', 'update_all_paragraph', 'non_update_all_paragraph_with_references', 'non_update_all_paragraph', 'non_update_first_paragraph', 'update_wiki_summary', 'non_update_wiki_summary', 'wiki_portal_summary', 'citation_position', 'event_wcep_id'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0].keys()\n",
    "# title_non_update_link\n",
    "# title_update_link\n",
    "# update_bs4\n",
    "# non_update_bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821ed47-256e-4b82-b46d-47e0fd79b941",
   "metadata": {},
   "source": [
    "### Get the indices of required instances\n",
    "* Keeep English language, with non-updated full-content existed, and meaningful updated full-content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a99b7f5f-256f-469c-851d-2ae8486682f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 232)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create idx list\n",
    "all_idx = [i for i in range(len(clusters))]\n",
    "rmved_idx = []\n",
    "\n",
    "for idx in range(len(clusters)):\n",
    "    try:\n",
    "        if bool(len(clusters[idx]['non_update_all_paragraph'].split('. ')) == 1):\n",
    "            rmved_idx.append(idx)\n",
    "    except:\n",
    "        error_idx.append(idx)\n",
    "idx_list = Diff(all_idx, rmved_idx)\n",
    "len(all_idx), len(idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1939a2d5-7574-4f8d-a5f2-5aae48ff246f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 226)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmved_idx = []\n",
    "for idx in idx_list:\n",
    "    if len(clusters[idx]['update_first_paragraph'].split())<=10:\n",
    "        rmved_idx.append(idx)\n",
    "id_list = Diff(idx_list, rmved_idx)\n",
    "len(idx_list), len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae3467a-a01a-4a7a-9c95-83c9749368fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 201)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by language of summ==English\n",
    "en_ids = []\n",
    "for idx in id_list:\n",
    "    if isEnglish(clusters[idx]['wiki_portal_summary']):\n",
    "        en_ids.append(idx)\n",
    "len(id_list), len(en_ids)\n",
    "# after filtering, we have 201 instances in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e3badb8e-3790-4ecb-a074-799bd959e24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 6]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bdf0fa-1c5f-4812-aeab-0d0ddcc669e7",
   "metadata": {},
   "source": [
    "### Parse the unicode into text\n",
    "* Parse the unicode into text\n",
    "* Paragraphs are separate with `. \\\\c\\\\c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1f89c23-5525-4ccb-a954-ad2e0cdebd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "with open(\"test_text.txt.src\", \"w\") as f:\n",
    "    for idx in en_ids:\n",
    "        bef_rec = []\n",
    "        non_update_all_paragraph = clusters[idx]['non_update_all_paragraph'].split('\\n')\n",
    "        bef_rec.extend(non_update_all_paragraph)\n",
    "        s = '.\\c'\n",
    "        bef_rec_str = s.join(bef_rec).replace(\"\\\\\\\\\\c\", \"\\c\\c\")\n",
    "        with contextlib.redirect_stdout(fwrite):\n",
    "            print({unicodedata.normalize('NFKD', bef_rec_str).encode('utf-8', 'ignore').decode('utf-8')})\n",
    "with open(\"test_text.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        log.append(line.strip().replace(\".\\\\\\\\c\", \"\\c\\c\").replace(\"\\\\\\'s\", \"'s\").replace(\"{\\'\", \"\").replace(\"\\'}\", \"\").replace(\".\\\\c\\\\c\", \". \\\\c\\\\c\"))\n",
    "with open(\"test_text.txt.src\", \"w\") as f:\n",
    "    for line in log:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd382e9d-1043-438a-82b5-3ab5db34e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "with open(\"test_text.txt.tgt\", \"w\") as f:\n",
    "    for idx in en_ids:\n",
    "        tgt_rec = []\n",
    "        update_all_paragraph = clusters[idx][\"update_all_paragraph\"].split(\"\\n\")\n",
    "        tgt_rec.extend(update_all_paragraph)\n",
    "        s = \".\\c\"\n",
    "        tgt_rec_str = s.join(tgt_rec).replace(\"\\\\\\\\\\c\", \"\\c\\c\")\n",
    "        with contextlib.redirect_stdout(f):\n",
    "            print({unicodedata.normalize('NFKD', bef_rec_str).encode('utf-8', 'ignore').decode('utf-8')})\n",
    "with open(\"test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        log.append(line.strip().replace(\".\\\\\\\\c\", \"\\c\\c\").replace(\"\\\\\\'s\", \"'s\").replace(\"{\\'\", \"\").replace(\"\\'}\", \"\").replace(\".\\\\c\\\\c\", \". \\\\c\\\\c\"))\n",
    "with open(\"test_text.txt.tgt\", \"w\") as f:\n",
    "    for line in log:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180b606-e927-476d-9da0-7784458e0814",
   "metadata": {},
   "source": [
    "### Extract the section name and number of paragraphs under each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "9146defc-93f5-48f4-b83a-b789b1dcb087",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'References' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[515], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: mod_secs[idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(mod_secs[idx]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m all_secs[idx]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get the section names except \"References\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[43mmod_secs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReferences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m sec_names \u001b[38;5;241m=\u001b[39m mod_secs[:end_idx]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Count the #paragraphs under each section (main section and sub-section), exclude the section with zero paragraph \u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'References' is not in list"
     ]
    }
   ],
   "source": [
    "raw_text = clusters[6][\"non_update_bs4\"]\n",
    "# end_idx = re.findall('<span class=\"mw-headline\" id=.+\">(.*)</span>', raw_text).index(\"References\")\n",
    "# sec_names = re.findall('<span class=\"toctext\">(.*)</span>', raw_text)[:end_idx]\n",
    "\n",
    "main_secs = re.findall('<span class=\"tocnumber\">\\d+</span> <span class=\"toctext\">(.*)</span>', raw_text)\n",
    "all_secs = re.findall('<span class=\"mw-headline\" id=.+\">(.*)</span>', raw_text)\n",
    "\n",
    "# Return the global index of main section\n",
    "main_global_ids = []\n",
    "for main_sec in main_secs:\n",
    "    # The indices of main sec in all_secs\n",
    "    ids = all_secs.index(main_sec)\n",
    "    main_global_ids.append(ids)\n",
    "\n",
    "# Return the parent section for each sub-section\n",
    "mod_secs = all_secs.copy()\n",
    "main_rec = []\n",
    "for idx in range(len(all_secs)):\n",
    "    for idd in main_global_ids:\n",
    "        if idx==idd: \n",
    "            mod_secs[idx] = mod_secs[idx]\n",
    "            main_rec.append(idd)\n",
    "        else: mod_secs[idx] = all_secs[main_rec[-1]]\n",
    "\n",
    "# Concatenate the parent section name with sub-section name\n",
    "for idx in range(len(all_secs)):\n",
    "    if all_secs[idx]==mod_secs[idx]: mod_secs[idx]==mod_secs[idx]\n",
    "    else: mod_secs[idx] = str(mod_secs[idx]) + \" \" + all_secs[idx]\n",
    "\n",
    "# Get the section names except \"References\"\n",
    "end_idx = mod_secs.index(\"References\")\n",
    "sec_names = mod_secs[:end_idx]\n",
    "\n",
    "# Count the #paragraphs under each section (main section and sub-section), exclude the section with zero paragraph \n",
    "num_pars = []\n",
    "for i in range(len(sec_names)):\n",
    "    pars_str = str(clusters[8][\"non_update_bs4\"].split('<span class=\"mw-headline')[i+1])\n",
    "    num_par = len(re.split(\"<p>|<li>\", pars_str)[1:])\n",
    "    num_pars.append(num_par)\n",
    "sec_pars = dict(zip(sec_names, num_pars))\n",
    "secs_pars_nums = {k: v for k, v in sec_pars.items() if v!=0}\n",
    "\n",
    "if \"Notes\" in secs_pars_nums.keys(): del secs_pars_nums[\"Notes\"]\n",
    "elif \"See also\" in secs_pars_nums.keys(): del secs_pars_nums[\"See also\"]\n",
    "\n",
    "secs_pars_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "0a9001b5-2448-4c71-87ec-c2ac99eb5aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background', 'Timeline', 'Vaccination', 'References']"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = clusters[6][\"non_update_bs4\"]\n",
    "# end_idx = re.findall('<span class=\"mw-headline\" id=.+\">(.*)</span>', raw_text).index(\"References\")\n",
    "# sec_names = re.findall('<span class=\"toctext\">(.*)</span>', raw_text)[:end_idx]\n",
    "\n",
    "main_secs = re.findall('<span class=\"tocnumber\">\\d+</span> <span class=\"toctext\">(.*)</span>', raw_text)\n",
    "all_secs = re.findall('<span class=\"mw-headline\" id=.+\">(.*)</span>', raw_text)\n",
    "all_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "00d4235d-bbe8-40af-af43-5e7d3bb60ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/w/index.php?title=COVID-19_pandemic_in_Palau&oldid=1032871488'"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[6][\"title_non_update_link\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "fd31ff04-8142-4a18-af72-645ec9b426e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 6,\n",
       " 8,\n",
       " 13,\n",
       " 25,\n",
       " 28,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 47,\n",
       " 48,\n",
       " 68,\n",
       " 71,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 86,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 94,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 124,\n",
       " 128,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 137,\n",
       " 138,\n",
       " 141,\n",
       " 144,\n",
       " 146,\n",
       " 149,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 168,\n",
       " 172,\n",
       " 176,\n",
       " 180,\n",
       " 182,\n",
       " 190,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 199,\n",
       " 200,\n",
       " 209,\n",
       " 210,\n",
       " 213,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 221,\n",
       " 222,\n",
       " 227,\n",
       " 230,\n",
       " 231,\n",
       " 236]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_ids = []\n",
    "for idx in en_ids:\n",
    "    try:\n",
    "        raw_text = clusters[idx][\"non_update_bs4\"]\n",
    "        end_idx = re.findall('<span class=\"toctext\">(.*)</span>', raw_text).index(\"See also\")\n",
    "    except:\n",
    "        error_ids.append(idx)\n",
    "error_ids\n",
    "# len(error_ids) # id: 2 and others\n",
    "# raw_text = clusters[2][\"non_update_bs4\"]\n",
    "# end_idx = re.findall('<span class=\"toctext\">(.*)</span>', raw_text)\n",
    "# raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89036952-3f0c-4d2b-b12b-4b7e6c48838b",
   "metadata": {},
   "source": [
    "* Since full-article includes \"summary\", we have to remove the \"summary\" before alignment -> then add back to the text afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ed5c2adc-907a-4f64-9056-8682ab1b784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "# summary = clusters[2][\"non_update_wiki_summary\"]\n",
    "contents_with_summ = []\n",
    "with open(\"test_text.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        contents_with_summ.append(line)\n",
    "\n",
    "for idx in range(len(en_ids)):\n",
    "    real_id = en_ids[idx]\n",
    "    s = \"\\\\c\\\\c\"\n",
    "    summs = clusters[real_id][\"non_update_wiki_summary\"].split(\"\\n\") # splitted summary\n",
    "    full_content_with_summ = contents_with_summ[idx]\n",
    "    with_summs = full_content_with_summ.split(\"\\\\c\\\\c\") # splitted contents with summ\n",
    "    for par in with_summs:\n",
    "        if par in summs: with_summs.remove(par) \n",
    "with open(\"test_no_summs.txt.src\", \"w\") as f:\n",
    "    for line in with_summs: f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "07639809-303f-4fbe-9506-5d369b31db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_summs = []\n",
    "with open(\"test_no_summs.txt.src\", \"r\") as f:\n",
    "    for line in f.readlines(): no_summs.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a94717c2-41a7-4313-bdef-5f646b18f15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In March and April 2021, Russia started to mass thousands of military personnel and equipment near its border with Ukraine, representing the highest force mobilization since the country's annexation of Crimea in 2014. This precipitated an international crisis and generated concerns over a potential invasion. Satellite imagery showed movements of armor, missiles, and heavy weaponry. The troops were partially removed by June. The crisis was renewed in October and November 2021, when over 100,000 Russian troops were again massed near the border by December. \\n\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_summs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9e412-1582-4263-9b02-b136ce76d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_with_summ[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f391c07-faa0-4210-9c7f-ea2d303f409e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-venv",
   "language": "python",
   "name": "data-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
