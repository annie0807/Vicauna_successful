{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b4816e6b-5f77-4121-8d98-0232a9f72b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import difflib\n",
    "from difflib import SequenceMatcher\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e94588-015e-443d-8099-69b4b0b021c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = torch.load('./ptfile/train.pt')\n",
    "test_pt = torch.load('./ptfile/test.pt')\n",
    "val_pt = torch.load('./ptfile/val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4d8a6f-eb59-4e32-b676-e807bbc5974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pt)\n",
    "# len(full_test_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e2a48b0-b2ad-47d8-9aec-5b04df2e1840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'summary'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pt[0].keys()\n",
    "# full_test_pt[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89e0e738-fabc-4a1d-9913-42369e9745d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_idx = []\n",
    "# for idx in range(len(train_pt)):\n",
    "#     tag = len(train_pt[idx]['document'].split('\\n\\n')) == len(train_pt[idx]['summary'].split('\\n\\n'))\n",
    "#     error_idx.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72d30f0-cb38-410b-82a2-4883097b5bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egypt–Russia relations (Russian: Российско-египетские отношения) refer to bilateral relations between Egypt and Russia. Diplomatic relations between the Soviet Union and Egypt were established on August 26, 1943. Egypt has an embassy in Moscow, while Russia has an embassy in Cairo and a consulate-general in Alexandria.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pt[5]['document'].split('.\\n\\n')[0].strip()\n",
    "\n",
    "# full_test_pt[7]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "142a9b08-5ddc-43f3-8629-6f81e36347ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egypt–Russia relations (Russian: Российско-египетские отношения) refer to bilateral relations between Egypt and Russia. Diplomatic relations between the Soviet Union and Egypt were established on August 26, 1943. Egypt has an embassy in Moscow, while Russia has an embassy in Cairo and a consulate-general in Alexandria.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pt[5]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56662ef-2a83-4a93-bf4f-74e72f46b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_test_pt[7]['summary']\n",
    "test_pt_ori[5]['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a3f7ab-6a31-4cd1-8103-0f27a0e783c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "too_much = []\n",
    "for idx in range(len(full_test_pt)):\n",
    "    if (len(full_test_pt[idx]['summary'].split('\\n\\n'))-len(full_test_pt[idx]['document'].split('\\n\\n'))) > 5:\n",
    "        too_much.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614a9b84-df6d-4b33-998c-b8da57f31594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(full_test_pt[7]['summary'].split('\\n\\n')) - len(full_test_pt[7]['document'].split('\\n\\n'))\n",
    "len(too_much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ad2e80-2331-4718-ab4e-b564a735281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict = {'un_matched_indices': too_much}  \n",
    "       \n",
    "# df = pd.DataFrame(dict) \n",
    "    \n",
    "# # saving the dataframe\n",
    "# df.to_csv('indices.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5589bdca-9ad1-4df0-aa96-8bdc83cccae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1602"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labeled_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b5a44-924f-49ac-92bc-d5fcda602ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_fix[12]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b607d-8c9b-49f0-93d8-36169fa759b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt[12]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "385fa047-3737-41cb-969b-b877d42460df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 191)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labeled_fix[1]['content'].split('#####')), len(train_pt[1]['summary'].split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83401ef-2321-484c-9d70-f7a7217dabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pars = []\n",
    "for idx in range(len(train_pt)):\n",
    "    # num_pars.append(len(train_pt[idx]['document']))\n",
    "    if len(train_pt[idx]['document'])!=1:\n",
    "        num_pars.append(idx)\n",
    "# np.max(num_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88bff8d0-116c-4ce6-96c9-ae20d04f93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_str = []\n",
    "for idx in range(len(test_pt)):\n",
    "    single_sent = test_pt[idx]['document'].split('.\\n\\n')\n",
    "    num_articles = math.ceil(len(single_sent)/10) # might be 0 if #articles<10\n",
    "    check_less=0\n",
    "    articles = []\n",
    "    # define idex\n",
    "    if num_articles==0: # number of paragraphs < 10\n",
    "        start_ids = [0]\n",
    "    else:\n",
    "        start_ids = [x*10 for x in range(num_articles)]\n",
    "    s = '.\\n\\n'\n",
    "    for id in range(len(start_ids)):\n",
    "        if len(start_ids)==1:\n",
    "            single_str = s.join(single_sent)\n",
    "        else:\n",
    "            try:\n",
    "                if len(single_sent)>=start_ids[id] and len(single_sent)<start_ids[id+1]: \n",
    "                    single_sent_lst = single_sent[start_ids[id]:len(single_sent)]\n",
    "                    single_str = s.join(single_sent_lst)\n",
    "                if len(single_sent)>start_ids[id] and len(single_sent)>start_ids[id+1]: \n",
    "                    single_sent_lst = single_sent[start_ids[id]:start_ids[id+1]]\n",
    "                    single_str = s.join(single_sent_lst)\n",
    "            except:\n",
    "                if len(single_sent)>start_ids[id]:\n",
    "                    single_sent_lst = single_sent[start_ids[id]:len(single_sent)]\n",
    "                    single_str = s.join(single_sent_lst)\n",
    "                else:\n",
    "                    single_str = str(single_sent[-1])\n",
    "        articles.append(single_str)\n",
    "    output_str.append(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38ad5b51-a64f-4cf6-bfae-af71f1356670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46f8457e-9a10-4b5f-a6a7-b5857fd670e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrap = []\n",
    "src_strs = output_str.copy()\n",
    "\n",
    "for idx in range(len(src_strs)):\n",
    "    idx_content = {}\n",
    "    idx_content['document'] = src_strs[idx]\n",
    "    idx_content['summary'] = summ_clusters[idx]\n",
    "    wrap.append(idx_content)\n",
    "torch.save(wrap, 'wceptest_train.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b0041-fa69-4af1-870d-faa0df92e61c",
   "metadata": {},
   "source": [
    "### Calculate the similarity between non-updated summary and updated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92fda48a-b4df-454b-b803-ec1f572a4ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13 2.460674157303371 2.0\n",
      "1 13 2.404494382022472 2.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the #paragraphs of each clusters except news trigger\n",
    "lens_train_docs = [len(train_pt[idx]['document'].split('.\\n\\n')[:-1]) for idx in range(len(train_pt))]\n",
    "lens_train_summs = [len(train_pt[idx]['summary'].split('.\\n\\n')) for idx in range(len(train_pt))]\n",
    "print(np.min(lens_train_docs), np.max(lens_train_docs), np.mean(lens_train_docs), np.median(lens_train_docs))\n",
    "print(np.min(lens_train_summs), np.max(lens_train_summs), np.mean(lens_train_summs), np.median(lens_train_summs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cb79329-b21b-4db8-b311-35c4b1e1ae64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049062049062049064 1.0 0.9659677156343112 0.9989094757872705\n"
     ]
    }
   ],
   "source": [
    "ratios = []\n",
    "for idx in range(len(train_pt)):\n",
    "    doc = ' \\n\\n'.join(train_pt[idx]['document'].split('\\n\\n')[:-1]).replace('.  ', '. ') \n",
    "    summ = ' \\n\\n'.join(train_pt[idx]['summary'].split('\\n\\n')).replace('.  \\n\\n', '. \\n\\n')\n",
    "    ratios.append(SequenceMatcher(None, doc, summ).ratio())\n",
    "print(np.min(ratios), np.max(ratios), np.mean(ratios), np.median(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0dff1e4e-6bdd-4693-a41c-11bb96ab7131",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8904776355007463"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter >0.990\n",
    "filtered_ratios = [ratio for ratio in ratios if ratio<0.990]\n",
    "np.mean(filtered_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50230f59-4629-481a-9e8c-f4ec078a9364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1602, 485)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratios), len(filtered_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa593361-9180-4bde-ab29-6b6128acd39d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split pt into src and tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e828e865-d49e-499b-b3b9-7f5d11d34675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp/ptfile\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Downloads/gcp_tmp/ptfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1ac96ff6-6a30-44e8-a39c-d357258f2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = torch.load('./train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3018130d-4a1a-428c-b1d8-fd42d573433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugo Rafael Chávez Frías (IPA: [uɰo rafael tʃaβes fɾias]) (born July 28, 1954) is the 53rd and current President of Venezuela. As the leader of the Bolivarian Revolution, Chávez promotes his vision of democratic socialism, Latin American integration, and anti-imperialism. He is also an ardent critic of neoliberal globalization and  US foreign policy. \\\\c\\\\cA career military officer, Chávez founded the leftist Fifth Republic Movement after orchestrating a failed 1992 coup détat against former president Carlos Andrés Pérez. Chávez was elected President in 1998 on promises of aiding Venezuelas poor majority, and was reelected in 2000. Domestically, Chávez has launched massive Bolivarian Missions, whose goals are to combat disease, illiteracy, malnutrition, poverty, and other social ills. Abroad, Chávez has acted against the Washington Consensus by supporting alternative models of economic development, and has advocated cooperation among the worlds poor nations, especially those in Latin America. \\\\c\\\\cChávezs reforms have evoked exceptional controversy in Venezuela and abroad, receiving both criticism and praise. Venezuelans are split between those who say he has empowered the poor and stimulated economic growth, and those who say he is autocratic and has mismanaged the economy. Some foreign governments view Chávez as a threat to global oil prices and regional stability, while others welcome his bilateral trade and reciprocal aid agreements. \\\\c\\\\cIn May 2006, he was named one of Time magazines 100 most influential people. \\\\c\\\\cUnited States Representative Charles Rangel (D) also said in a press release that an attack on Bush is attack on all of us (Americans).'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pt[0]['document'].replace('.\\n\\n', '. \\n\\n')\n",
    "train_pt[0]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8e4a75ef-906d-4f54-88b3-5ff0390673d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugo Rafael Chávez Frías (IPA: [uɰo rafael tʃaβes fɾias]) (born July 28, 1954) is the 53rd and current President of Venezuela. As the leader of the Bolivarian Revolution, Chávez promotes his vision of democratic socialism, Latin American integration, and anti-imperialism.  He is also an ardent critic of neoliberal globalization and  US foreign policy. \\\\c\\\\cA career military officer, Chávez founded the leftist Fifth Republic Movement after orchestrating a failed 1992 coup détat against former president Carlos Andrés Pérez.  Chávez was elected President in 1998 on promises of aiding Venezuelas poor majority, and was reelected in 2000. Domestically, Chávez has launched massive Bolivarian Missions, whose goals are to combat disease, illiteracy, malnutrition, poverty, and other social ills. Abroad, Chávez has acted against the Washington Consensus by supporting alternative models of economic development, and has advocated cooperation among the worlds poor nations, especially those in Latin America. \\\\c\\\\cChávezs reforms have evoked exceptional controversy in Venezuela and abroad, receiving both criticism and praise. Venezuelans are split between those who say he has empowered the poor and stimulated economic growth, and those who say he is autocratic and has mismanaged the economy. Some foreign governments view Chávez as a threat to global oil prices and regional stability, while others welcome his bilateral trade and reciprocal aid agreements. \\\\c\\\\cIn May 2006, he was named one of Time magazines 100 most influential people'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '. \\c\\c'.join(train_pt[0]['document'].replace('.\\n\\n', '. \\n\\n').split('. \\n\\n')[:-1])\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "13e9a98b-f292-40f6-96c4-234dba9fcc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugo Rafael Chávez Frías (IPA: ) (born July 28, 1954) is the 53rd and current President of Venezuela. As the leader of the \"Bolivarian Revolution,\" Chávez promotes his vision of democratic socialism, Latin American integration, and anti-imperialism.  He is also an ardent critic of neoliberal globalization and  US foreign policy. \\\\c\\\\cA career military officer, Chávez founded the leftist Fifth Republic Movement after orchestrating a failed 1992 coup détat against former president Carlos Andrés Pérez.  Chávez was elected President in 1998 on promises of aiding Venezuelas poor majority, and was reelected in 2000. Domestically, Chávez has launched massive Bolivarian Missions, whose goals are to combat disease, illiteracy, malnutrition, poverty, and other social ills. Abroad, Chávez has acted against the Washington Consensus by supporting alternative models of economic development, and has advocated cooperation among the worlds poor nations, especially those in Latin America. \\\\c\\\\cChávezs reforms have evoked exceptional controversy in Venezuela and abroad, receiving both criticism and praise. Venezuelans are split between those who say he has empowered the poor and stimulated economic growth, and those who say he is autocratic and has mismanaged the economy. Some foreign governments view Chávez as a threat to global oil prices and regional stability, while others welcome his bilateral trade and reciprocal aid agreements. \\n\\nIn May 2006, he was named one of Time magazines 100 most influential people.'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = train_pt[0]['summary'].replace('.\\n\\n', '. \\\\c\\\\c')\n",
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6c7c3cd4-113e-4817-99a4-dd2bcb4132cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcs, tgts = [], []\n",
    "\n",
    "# for idx in range(len(train_pt)):\n",
    "#     # src = '. \\c\\c'.join(train_pt[idx]['document'].replace('.\\n\\n', '. \\n\\n').split('. \\n\\n')[:-1]).encode('utf-8', 'ignore').decode('utf-8')\n",
    "#     src = '. \\c\\c'.join(train_pt[idx]['document'].replace('\\n\\n', '.\\n\\n').replace('..\\n\\n', '.\\n\\n').replace('.\\n\\n', '. \\n\\n').split('. \\n\\n')[:-1]).encode('utf-8', 'ignore').decode('utf-8')\n",
    "#     # tgt = train_pt[idx]['summary'].replace('.\\n\\n', '. \\\\c\\\\c').replace('\\n\\n', '\\\\c\\\\c').encode('utf-8', 'ignore').decode('utf-8') \n",
    "#     tgt = train_pt[idx]['summary'].replace('\\n\\n', '.\\n\\n').replace('..\\n\\n', '.\\n\\n').replace('.\\n\\n', '. \\n\\n').replace('. \\n\\n', '. \\\\c\\\\c').encode('utf-8', 'ignore').decode('utf-8') \n",
    "#     srcs.append(src)\n",
    "#     tgts.append(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e53939f4-1d7c-48f7-8eb0-9c82a1c4ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs, tgts = [], []\n",
    "for idx in range(len(train_pt)):\n",
    "    srcs.append(' \\\\c\\\\c'.join(train_pt[idx]['document'].split(' \\\\c\\\\c')[:-1]))\n",
    "    tgts.append(train_pt[idx]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fb565960-6418-410b-abd3-319f1e643536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp/ptfile\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "aedeb540-1183-499b-9fa7-5ac86d7381a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.src', 'w') as f:\n",
    "    for line in srcs:\n",
    "        f.write(line+'\\n')\n",
    "with open('train.tgt', 'w') as f:\n",
    "    for line in tgts:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291c38e-b511-4e38-9cd7-1a24ca210251",
   "metadata": {},
   "source": [
    "### Calculate the ROUGE without trigger existed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9e7e3d1d-82da-4c59-b5a1-34e4d9a6bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Downloads/gcp_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e23cab94-b937-4000-8ca5-59b2c3b7d559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.9602756499203132,\n",
       "  'p': 0.9809746373851904,\n",
       "  'f': 0.9680553407150487},\n",
       " 'rouge-2': {'r': 0.9482270776940344,\n",
       "  'p': 0.9702044215681309,\n",
       "  'f': 0.9562910689671305},\n",
       " 'rouge-l': {'r': 0.959834044346764,\n",
       "  'p': 0.9805090578224864,\n",
       "  'f': 0.9676219908796095}}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import FilesRouge\n",
    "\n",
    "files_rouge = FilesRouge()\n",
    "hyp_path = '/Users/quert/Downloads/gcp_tmp/ptfile/train.src'\n",
    "# hyp_path = 'aft_test_rouge_sec_txt.src'\n",
    "# hyp_path = 'aft_test_rouge_txt.src'\n",
    "ref_path = '/Users/quert/Downloads/gcp_tmp/ptfile/train.tgt'\n",
    "scores = files_rouge.get_scores(hyp_path, ref_path, avg=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "306891c7-6310-46b2-a11e-e75358bf1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 482/482 [00:00<00:00, 190kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:01<00:00, 722kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:01<00:00, 439kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████| 1.43G/1.43G [01:06<00:00, 21.3MB/s]\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [14:44<00:00, 19.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:04<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 889.06 seconds, 1.80 sentences/sec\n",
      "System level F1 score: 0.991\n"
     ]
    }
   ],
   "source": [
    "# Calculate BERTScore\n",
    "from bert_score import score\n",
    "# with open(\"gen_summ/gen_summ.test.tgt\") as f:\n",
    "# with open(\"aft_model_txt.src\") as f:\n",
    "with open('/Users/quert/Downloads/gcp_tmp/ptfile/train.src') as f:\n",
    "    cands = [line.strip() for line in f]\n",
    "\n",
    "with open(\"/Users/quert/Downloads/gcp_tmp/ptfile/train.tgt\") as f:\n",
    "    refs = [line.strip() for line in f]\n",
    "P, R, F1 = score(cands, refs, lang='en', verbose=True)\n",
    "print(f\"System level F1 score: {F1.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690b44e1-2113-4308-ad16-c16c77b5bbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean the paragraph splitting tokens and rebuild pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "97290a8f-6375-4f45-8aab-cc99ae641cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = torch.load('./first/val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "78a7171d-7090-4f40-8593-2fe7f4fd6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs, tgts = [], []\n",
    "\n",
    "for idx in range(len(pt_file)):\n",
    "    # src = '. \\c\\c'.join(train_pt[idx]['document'].replace('.\\n\\n', '. \\n\\n').split('. \\n\\n')[:-1]).encode('utf-8', 'ignore').decode('utf-8')\n",
    "    src = '. \\c\\c'.join(pt_file[idx]['document'].replace('\\n\\n', '.\\n\\n').replace('..\\n\\n', '.\\n\\n').replace('.\\n\\n', '. \\n\\n').split('. \\n\\n')[:]).encode('utf-8', 'ignore').decode('utf-8').replace('.  ', '. ')\n",
    "    # tgt = train_pt[idx]['summary'].replace('.\\n\\n', '. \\\\c\\\\c').replace('\\n\\n', '\\\\c\\\\c').encode('utf-8', 'ignore').decode('utf-8') \n",
    "    tgt = pt_file[idx]['summary'].replace('\\n\\n', '.\\n\\n').replace('..\\n\\n', '.\\n\\n').replace('.\\n\\n', '. \\n\\n').replace('. \\n\\n', '. \\\\c\\\\c').replace('. . \\\\c\\\\c', '. \\\\c\\\\c').encode('utf-8', 'ignore').decode('utf-8') \n",
    "    srcs.append(src)\n",
    "    tgts.append(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "015c4b29-e125-40b2-9e82-5363d9c63705",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = []\n",
    "for idx in range(len(pt_file)):\n",
    "    idx_content = {}\n",
    "    summ_str = pt_file[idx]['summary']\n",
    "    idx_content['document'] = srcs[idx]\n",
    "    idx_content['summary'] = tgts[idx]\n",
    "    wrap.append(idx_content)\n",
    "torch.save(wrap, './val_rebuild.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "302699f3-8d75-4d3e-b94d-0c71cf6b25ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuild_pt = torch.load('./val_rebuild.pt')\n",
    "len(rebuild_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "55b6dfad-958e-425b-8f6f-e37f57d7262d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On March 29, 2021, Adam Toledo, a 13-year-old Mexican American boy, was fatally shot by Chicago Police Department officer Eric Stillman in the Little Village neighborhood on the West Side of Chicago. Bodycam footage of the shooting was released publicly on April 15. \\\\c\\\\cSeveral protests take place around the city after the video is released, including one that briefly shut down northbound Michigan Avenue and another at Union Park.'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuild_pt[2]['document']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b73e51-573d-463d-b432-37dbc36d5b60",
   "metadata": {},
   "source": [
    "### Calculate the #paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a7e349f7-a2a0-4ab3-b99d-64221a0f67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_pt = torch.load('./bs3_original/train.pt')\n",
    "train_pt = torch.load('./bs3/train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ce345366-bd95-4144-8a97-c47c79d759d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 191)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_train_pt[1]['document'].split('\\n\\n')), len(orig_train_pt[1]['summary'].split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2652b901-f9af-4141-8ddd-2058af6ece6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 191)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pt[1]['document'].split('\\\\c\\\\c')), len(train_pt[1]['summary'].split('\\\\c\\\\c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "963f0449-b6d3-4677-89e8-74e427258d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_orig = []\n",
    "lengths = []\n",
    "for idx in range(len(train_pt)):\n",
    "    lengths.append(abs(len(train_pt[idx]['document'].split('\\\\c\\\\c'))-len(train_pt[idx]['summary'].split('\\\\c\\\\c'))))\n",
    "    lengths_orig.append(abs(len(orig_train_pt[idx]['document'].split('\\n\\n'))-len(orig_train_pt[idx]['summary'].split('\\n\\n'))))\n",
    "lengths==lengths_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dbc23c-f72c-4895-a964-8204e81a0708",
   "metadata": {},
   "source": [
    "### Extract the trigger from instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1828e3be-1fd1-4aef-87a7-81d71a529f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = torch.load('bs3_original/train.pt')\n",
    "test_pt = torch.load('bs3_original/test.pt')\n",
    "val_pt = torch.load('bs3_original/val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "617a3d43-0d0d-4b2e-b893-c7800c96222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the trigger\n",
    "with open('triggers_train.src', 'w') as f:\n",
    "    for idx in range(len(train_pt)):\n",
    "        trigger = train_pt[idx]['document'].split('\\\\c\\\\c')[-1]\n",
    "        f.write(trigger+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "eef99030-068f-420e-be3d-1264322c72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the trigger\n",
    "with open('triggers_test.src', 'w') as f:\n",
    "    for idx in range(len(test_pt)):\n",
    "        trigger = test_pt[idx]['document'].split('\\\\c\\\\c')[-1]\n",
    "        f.write(trigger+'\\n')\n",
    "# extract the trigger\n",
    "with open('triggers_val.src', 'w') as f:\n",
    "    for idx in range(len(val_pt)):\n",
    "        trigger = val_pt[idx]['document'].split('\\\\c\\\\c')[-1]\n",
    "        f.write(trigger+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a0219-056f-4057-9233-b93336b76554",
   "metadata": {},
   "source": [
    "### Calculate the edit actions from labeled data (data from GCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f8db2b80-7160-4d16-a4d6-76936c472d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_test = torch.load('bs3_original/test_labeled.pt')\n",
    "train_without_trigger = torch.load('./train_labeled_without_trigger.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "70326609-344a-4c0e-8b66-96d50d428727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[KEEP] Hugo Rafael [KEEP] Chávez [KEEP] Frías [RM] (IPA: [uɰo rafael tʃaβes fɾias]) [RM] (born July 28, 1954) is the 53rd and current President of Venezuela. [ADD] (IPA: ) (born July 28, 1954) is the 53rd and current President of Venezuela. [RM] As the leader of the Bolivarian Revolution, Chávez promotes his vision of democratic socialism, Latin American integration, and anti-imperialism. [ADD] As the leader of the \"Bolivarian Revolution,\" Chávez promotes his vision of democratic socialism, Latin American integration, and anti-imperialism. [KEEP] He is also an ardent critic of neoliberal globalization and  US foreign policy. [KEEP] \\\\c\\\\cA career military officer, Chávez founded the leftist Fifth Republic Movement after orchestrating a failed 1992 coup détat against former president Carlos Andrés [KEEP] Pérez. [KEEP] Chávez was elected President in 1998 on promises of aiding Venezuelas poor majority, and was reelected in 2000. [KEEP] Domestically, Chávez has launched massive Bolivarian Missions, whose goals are to combat disease, illiteracy, malnutrition, poverty, and other social ills. [KEEP] Abroad, Chávez has acted against the Washington Consensus by supporting alternative models of economic development, and has advocated cooperation among the worlds poor nations, especially those in Latin America. [KEEP] \\\\c\\\\cChávezs reforms have evoked exceptional controversy in Venezuela and abroad, receiving both criticism and praise. [KEEP] Venezuelans are split between those who say he has empowered the poor and stimulated economic growth, and those who say he is autocratic and has mismanaged the economy. [KEEP] Some foreign governments view Chávez as a threat to global oil prices and regional stability, while others welcome his bilateral trade and reciprocal aid agreements. [KEEP] \\\\c\\\\cIn May 2006, he was named one of Time magazines 100 most influential people.'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_without_trigger[0]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2865bf-fef8-429a-a75a-d25a02de0d0b",
   "metadata": {},
   "source": [
    "### Truncate pt file to 10 instances for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "3e712d6f-8b43-4728-b70e-9cced0befb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pt = torch.load('bs3_original/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "e69e60fa-efbe-4f5f-a363-48f742df8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs, tgts = [], []\n",
    "for idx in range(10):\n",
    "    srcs.append(test_pt[idx]['document'])\n",
    "    tgts.append(test_pt[idx]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "147dae59-4bd4-4570-bc9f-e8b2c56f288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = []\n",
    "for idx in range(len(srcs)):\n",
    "    idx_content = {}\n",
    "    idx_content['document'] = srcs[idx]\n",
    "    idx_content['summary'] = tgts[idx]\n",
    "    wrap.append(idx_content)\n",
    "torch.save(wrap, './bs3_original/eva_par.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73fb26-2d40-4408-8417-7cd24b408710",
   "metadata": {},
   "source": [
    "* Feed `\\\\c\\\\c` as splitting token, and mark `</p><p>` in script, it would do well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5580d-aeb2-46be-83de-2e9bb214a592",
   "metadata": {},
   "source": [
    "### Convert the pt file to csv for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eca0808b-f8d9-42fb-9c20-4af11524ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pt = torch.load(\"./ptfile/bs3_original/train.pt\")\n",
    "test_pt = torch.load(\"./ptfile/bs3_original/test.pt\")\n",
    "val_pt = torch.load(\"./ptfile/bs3_original/val.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2882f5cd-cc4b-4861-9d6b-0421260cba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, summaries = [], []\n",
    "for idx in range(len(train_pt)):\n",
    "    document = train_pt[idx][\"document\"]\n",
    "    summary = train_pt[idx][\"summary\"]\n",
    "    documents.append(document)\n",
    "    summaries.append(summary)\n",
    "pd.DataFrame({\"document\": documents, \"summary\": summaries}).to_csv(\"./ptfile/same_secs_insert_labeled/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5ee762-c0a1-485d-a903-8de8c9881d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2abe9-0f43-43d8-82fb-af1b7c3ef617",
   "metadata": {},
   "source": [
    "### Extract the positive instances from classification report for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1fc7ec12-f065-4681-9716-34273732bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_csv = pd.read_csv(\"./ptfile/same_secs_insert_labeled/submission.csv\")\n",
    "test_csv = pd.read_csv(\"./ptfile/same_secs_insert_labeled/merged_updated_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c8ce73d2-b9ae-40e7-b0a2-45dc74c808ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the positive instances\n",
    "targets = sub_csv.target.values\n",
    "instances = test_csv.paragraph.values\n",
    "pos_ids = [idx for idx in range(len(targets)) if targets[idx]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5b862a99-6806-4a30-822b-29ae57c6a476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 10054)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_ids), len(targets)-len(pos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6cc79d01-0236-4cec-844b-bb8c9a08bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_instances = [instances[idx] for idx in pos_ids]\n",
    "pd.DataFrame({\"document\": pos_instances}).to_csv(\"./ptfile/same_secs_insert_labeled/pos_classification.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdf191-f924-4eaf-966d-7408a8ec6d1d",
   "metadata": {},
   "source": [
    "### Merge the generated (updated) paragraphs with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "b213c40d-34a7-4ad4-811e-e80a529a5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated_ins = pd.read_csv(\"./ptfile/same_secs_insert_labeled/generated_paragraphs.csv\").paragraph.values\n",
    "updated_ins = []\n",
    "with open(\"./chatgpt_output.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        updated_ins.append(line)\n",
    "len(updated_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "f59d572b-5a0a-4d52-af61-cd3a84b7413c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"./ptfile/same_secs_insert_labeled/merged_updated_test.csv\")\n",
    "instances = test_csv.paragraph.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "ac49809c-8229-4ddc-b6b6-fd81d261e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_instances = instances.copy()\n",
    "for idx in range(len(pos_ids)):\n",
    "    merged_instances[pos_ids[idx]] = updated_ins[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "id": "bd47a513-cdd7-46d7-91fa-a1abe898d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"paragraph\": merged_instances}).to_csv(\"./ptfile/same_secs_insert_labeled/updated_file_chatgpt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61cb51-63a4-462f-8fda-9779c079b047",
   "metadata": {},
   "source": [
    "### Re-construct the paragraphs to its corresponded instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "id": "ab951917-08e4-4a4b-b613-bcf158fd8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_df = pd.read_csv(\"./ptfile/same_secs_insert_labeled/merged_numpar_test.csv\")\n",
    "updated_df = pd.read_csv(\"./ptfile/same_secs_insert_labeled/updated_file_chatgpt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "id": "da738c57-3363-4009-a248-a9edbdf654f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   Unnamed: 0   168 non-null    int64\n",
      " 1   Num of pars  168 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 2.8 KB\n"
     ]
    }
   ],
   "source": [
    "nums_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "e0dc9d89-3d97-4c58-98d4-6c46ba86bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   Unnamed: 0  168 non-null    int64\n",
      " 1   nums        168 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 2.8 KB\n"
     ]
    }
   ],
   "source": [
    "nums_df.rename(columns={'Num of pars': 'nums'}, inplace=True)\n",
    "nums_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "db40e65b-144d-4623-a9e8-42b67ae0384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = list(nums_df.nums.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "16e08648-6e00-48c9-89b1-8554efa0b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_instances = []\n",
    "start = 0\n",
    "for num in nums:\n",
    "    end = start + num - 1\n",
    "    # sel_range = [start, end]\n",
    "    txt_in_range = updated_df.iloc[start:end+1, 1].to_list()\n",
    "    instance = \". \".join(txt_in_range)\n",
    "    hyp_instances.append(instance)\n",
    "    start += num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "71253af1-e030-4ce1-aa63-67a3b9cd38cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pt = torch.load(\"./ptfile/same_secs_insert_labeled/test_samesecs_labeled.pt\")\n",
    "ref_instances = []\n",
    "for idx in range(len(test_pt)):\n",
    "    ref_instances.append(test_pt[idx][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "a158f3bb-83ae-4516-90db-a81bd20a8587",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(hyp_instances)==len(ref_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "88bcf013-a877-4e5d-a7ec-e94a49f8bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"hyp\": hyp_instances, \"ref\": ref_instances}).to_csv(\"./ptfile/same_secs_insert_labeled/final_merged_chatgpt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "91f5437b-e328-4bc6-afb7-5b858283e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ptfile/same_secs_insert_labeled/final_hyp_chatgpt.src\", \"w\") as f:\n",
    "    for line in hyp_instances:\n",
    "        line = line.replace(\"\\n\", \"\\c\")\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "d985180a-8103-4db3-93ec-974919cdbf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/final_hyp_chatgpt.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        check.append(line)\n",
    "len(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9dd3bd-1a3d-4ea9-b4aa-7d04389d96c0",
   "metadata": {},
   "source": [
    "### Generate prompts with contents to feed into ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "08bc9475-5bde-48b2-a03a-80dd9780479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pt = torch.load(\"./ptfile/same_secs_insert_labeled/test.pt\")\n",
    "test_csv = pd.read_csv(\"./ptfile/same_secs_insert_labeled/merged_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "343fd757-2a96-4860-8c6a-82be32477273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the needed idx from `pos_ids`\n",
    "old_contents, triggers_for_gpt = [], []\n",
    "for idx in pos_ids:\n",
    "    old_contents.append(test_csv.iloc[idx, 0])\n",
    "    triggers_for_gpt.append(test_csv.iloc[idx, 1])\n",
    "assert len(old_contents)==len(triggers_for_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "d2f8f8ac-5828-4d80-a49d-dd04ba90b11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Ukrainian government accuses Russian separatists of shelling a kindergarten in Stanytsia Luhanska, Luhansk Oblast using artillery, injuring three civilians. The Luhansk People's Republic says that its forces were attacked by the Ukrainian military with mortars, grenade launchers and machine gun fire. At least 32 shells hit the city, causing power outages and damaging multiple structures.  \\n\""
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 370\n",
    "# old_contents[idx]\n",
    "triggers_for_gpt[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ed9a0-c0e1-471b-940c-0314ae05332a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "8f98bb8e-22f5-47b7-a700-e7f71b91170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Downloads/gcp_tmp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ~/Downloads/gcp_tmp\n",
    "old_info = []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/original_test.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        old_info.append(line.strip())\n",
    "len(old_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "261ab226-28bc-4630-9995-0e7f2ab8f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the triggers\n",
    "triggers = []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/samesecs_triggers_test.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        triggers.append(line.strip())\n",
    "len(triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f1e2c28e-b187-4257-a75b-b09c61e3f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "# openai.api_key = \"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\"\n",
    "# openai.api_key = \"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\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "6fa8dc91-85b8-4e7e-9efd-21209380bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_mul = []\n",
    "for idx in range(len(old_info)):\n",
    "    input_single = f\"\"\"\n",
    "As an article writer, you have to update an article given its old version and updated with the new information.\\n\n",
    "Here's the OLD version and the new information, and you have to give me the updated version in one paragraph.\\n\n",
    "OLD VERSION:\\n\n",
    "{old_info[idx]}\n",
    "\\nNEW INFORMATION:\n",
    "{triggers[idx]}\n",
    "\"\"\"\n",
    "    inputs_mul.append(input_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "f5cf31da-1549-407a-a063-96826eec69ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3871 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 1252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the instances length with shorter than 4096\n",
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "short_idx = []\n",
    "for idx in range(len(inputs_mul)):\n",
    "    input_len = len(tokenizer(inputs_mul[idx])[\"input_ids\"])\n",
    "    # if len(inputs_mul[idx].split()) < 4096:\n",
    "    if input_len < 3900:\n",
    "        short_idx.append(idx)\n",
    "len(short_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "55bdb33d-b06b-46a6-a067-3c5d5dab4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for idx in short_idx:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": inputs_mul[idx]}\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "f88ae42b-916e-42fa-8fc0-f0ac9635373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"idx\": short_idx, \"response\": responses}).to_csv(\"./ptfile/same_secs_insert_labeled/chatgpt_min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "id": "28507055-6fb9-4e35-a138-5e46b0cb70c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the respective instances from our data\n",
    "# merge the updated gpt with others data\n",
    "\n",
    "our_hyp = []\n",
    "with open(\"./ptfile/same_secs_insert/test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        our_hyp.append(line.strip())\n",
    "len(our_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "626af438-6119-46ee-8c5c-22195b2bb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract our experiments with short indices\n",
    "our_short_data = []\n",
    "for idx in short_idx:\n",
    "    our_short_data.append(our_hyp[idx])\n",
    "with open(\"./ptfile/same_secs_insert_labeled/chatgpt/final_ref_short.tgt\", \"w\") as f:\n",
    "    for line in our_data:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "3561e8bf-ba75-4acf-8234-2b9268ec6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = []\n",
    "chatgpt_full_csv = pd.read_csv(\"./ptfile/same_secs_insert_labeled/chatgpt/chatgpt_full.csv\")\n",
    "for idx in range(len(chatgpt_full_csv)):\n",
    "    gpt_output.append(chatgpt_full_csv.iloc[idx, 2])\n",
    "with open(\"./ptfile/same_secs_insert_labeled/chatgpt/chatgpt_full.src\", \"w\") as f:\n",
    "    for line in gpt_output:\n",
    "        f.write(line.strip()+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "id": "5223d860-4e8a-44db-90a7-6bc49d92d880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/chatgpt/chatgpt_full.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        check.append(line)\n",
    "len(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "id": "9ee7df7c-33d8-478d-9278-fa78ba7d6005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Taliban continues its 2021 offensive against the government of Afghanistan and has captured its first major provincial capital since the 2001 invasion, with the capture of Zaranj, the provincial capital of Nimruz Province. The lack of reinforcements from the central government is being blamed for the fall of the city into Taliban control. As of 21 August, the Taliban has reportedly captured around two-thirds of the country and is now moving towards major cities, including Kabul. The international community, including the United States, has expressed concerns over the deteriorating security situation and the potential for a humanitarian crisis. Meanwhile, the Afghan government has vowed to retake all seized districts by the Taliban, and local militias have formed to fight against the group, including the People's Resistance Movement of Western Afghanistan in Herat Province.\""
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_full_csv.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9aeafe-5e32-4f2b-9018-550ece1e957e",
   "metadata": {},
   "source": [
    "### Few-shots for ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "d6bc59f7-608d-456f-be5d-b423e17c5c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 1159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gts = []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/original_test.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        gts.append(line.strip())\n",
    "        \n",
    "gts_short = []\n",
    "for idx in short_idx:\n",
    "    gts_short.append(gts[idx].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "id": "f16edf32-44cc-463b-9db6-6a16df58a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the instances with low rouge scores on ground truth but highest scores on predictions (according our two-staged BART)\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "hyps, refs = [], []\n",
    "with open(\"./ptfile/same_secs_insert_labeled/final_hyp.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        hyps.append(line.strip())\n",
    "        \n",
    "with open(\"./ptfile/same_secs_insert_labeled/final_ref.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        refs.append(line.strip())\n",
    "assert len(hyps)==len(refs)\n",
    "    \n",
    "hyp_refs_scores = []\n",
    "for idx in range(len(hyps)):\n",
    "    hyp_refs_scores.append(scorer.score(hyps[idx], refs[idx])[\"rougeL\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "id": "4bfc4e55-02eb-475f-bcdf-a1c1cd96d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the scores between hyps, refs according to our indices\n",
    "hyp_refs_scores_short = []\n",
    "for idx in short_idx:\n",
    "    hyp_refs_scores_short.append(hyp_refs_scores[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "id": "bef4d7ab-01bc-4489-8cfc-2d19b6e2b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scores between ground truths and references\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "gts_refs_scores = []\n",
    "for idx in range(len(short_idx)):\n",
    "    gts_refs_scores.append(scorer.score(gts_short[idx], refs[idx])[\"rouge1\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "id": "9ad3f830-d3d3-4cfd-b3de-d80344d83d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "min_value = min(hyp_refs_scores_short)\n",
    "min_index = hyp_refs_scores_short.index(min_value)\n",
    "print(min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5596c7-d627-4139-b700-1d823d40e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 1202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyp_refs_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08ef0327-8715-4a56-9370-ad6d9277d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pt file for gcp computing the edit actions {\"document\": hyp, \"summary\": ref}\n",
    "hyps, refs = [], []\n",
    "with open(\"./final_hyp.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        hyps.append(line.strip())\n",
    "\n",
    "with open(\"../same_secs_insert/test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        refs.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa389fca-f11c-42f2-8ba6-5f8685a52ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = []\n",
    "\n",
    "for idx in range(len(hyps)):\n",
    "    idx_content = {}\n",
    "    idx_content['document'] = hyps[idx]\n",
    "    idx_content['summary'] = refs[idx]\n",
    "    wrap.append(idx_content)\n",
    "torch.save(wrap, './ptfile/same_secs_insert_labeled/final_exp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113fbd57-7a38-4bad-8939-aed578546f15",
   "metadata": {},
   "source": [
    "### Fix the problem of `final_hyp.src`, `final_ref.tgt`, `final_exp.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18a8d5f4-7b0c-4e43-ab66-9bb5304c4191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  168 non-null    int64 \n",
      " 1   hyp         168 non-null    object\n",
      " 2   ref         168 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "final_merged = pd.read_csv(\"./final_merged.csv\")\n",
    "final_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21e02f73-ea99-4819-868b-1522e2127faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps, refs = [], []\n",
    "for idx in range(len(final_merged)):\n",
    "    hyps.append(final_merged.iloc[idx, 1].strip())\n",
    "    refs.append(final_merged.iloc[idx, 2].strip())\n",
    "assert len(hyps)==len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8a06d7d9-3247-41b8-86c0-1a4fdbcd9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./final_hyp.src\", \"w\") as f:\n",
    "    for line in hyps:\n",
    "        f.write(line+\"\\n\")\n",
    "with open(\"./final_ref.tgt\", \"w\") as f:\n",
    "    for line in refs:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4e5263cd-da8c-417f-b461-e891988ea865",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_check, refs_check = [], []\n",
    "with open(\"./final_hyp.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        hyps_check.append(line)\n",
    "with open(\"./final_ref.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        refs_check.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5f7b7769-48f9-4ede-8fd5-773b7189af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the src and tgt into pt file\n",
    "wrap = []\n",
    "for idx in range(len(hyps_check)):\n",
    "    idx_content = {}\n",
    "    idx_content['document'] = hyps_check[idx]\n",
    "    idx_content['summary'] = refs_check[idx]\n",
    "    wrap.append(idx_content)\n",
    "torch.save(wrap, './final_exp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1edcc2-f774-4cfc-b2e4-6db1a297880a",
   "metadata": {},
   "source": [
    "### Prepare few-shots on ChatGPT (GPT-3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "170d9231-b005-428b-97a3-56835d3af6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_labeled = torch.load(\"./chatgpt-fewshots/exp_labeled.pt\")\n",
    "exp_pt = torch.load(\"./final_exp.pt\")\n",
    "test_labeled_orig = torch.load(\"./test_samesecs_labeled.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "1d936eaa-6bd6-4fa4-98ce-9585885f2e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers = []\n",
    "with open(\"./samesecs_triggers_test.txt\", \"r\") as f:\n",
    "     for line in f.readlines():\n",
    "            triggers.append(line.strip())\n",
    "len(triggers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "a0a0bb86-fd07-48a1-88e8-5cae7df4dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olds = []\n",
    "for idx in range(len(test_labeled_orig)):\n",
    "    olds.append(test_labeled_orig[idx][\"document\"].strip())\n",
    "len(olds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0a93bfc3-18a5-4103-8be4-a5e0a3847afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 168)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = []\n",
    "# with open(\"./original_test.src\", \"r\") as f:\n",
    "#     for line in f.readlines():\n",
    "#         olds.append(line.strip())\n",
    "        \n",
    "with open(\"../same_secs_insert/test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        news.append(line.strip())\n",
    "len(olds), len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "bfea7f34-5dcd-4f09-abf8-69e09e3c6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shots_prompts = []\n",
    "for idx in range(len(olds)):\n",
    "    few_shots_prompt = f\"\"\"\n",
    "As an article writer, you have to update an article given its old version and a triggered news event.\\n\n",
    "Here's the example of OLD version, the news information, and the updated version.\\n\n",
    "OLD VERSION:\\n\n",
    "{olds[idx]}\n",
    "\\nNEWS INFORMATION:\\n\n",
    "{triggers[idx]}\n",
    "\\nUPDATED VERSION:\\n\n",
    "{news[idx]}\n",
    "\"\"\"\n",
    "    few_shots_prompts.append(few_shots_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "4f14fddb-7e61-4bc7-9b1b-0d69684c0f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7651 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the prompts length with shorter than 4096\n",
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "short_idx = []\n",
    "for idx in range(len(few_shots_prompts)):\n",
    "    input_len = len(tokenizer(few_shots_prompts[idx])[\"input_ids\"])\n",
    "    if input_len < 3900:\n",
    "        short_idx.append(idx)\n",
    "len(short_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "54db704f-6896-42c8-9214-6f89d8ffb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the editions from the indices which has the acceptable input length of prompts\n",
    "import re\n",
    "\n",
    "sum_editions = []\n",
    "for idx in short_idx:\n",
    "    editions = []\n",
    "    for par in test_labeled_orig[idx][\"summary\"].split(\"\\\\c\\\\c\"):\n",
    "        num_editions = len(re.findall(r\"\\[ADD]\", par)) + len(re.findall(r\"\\[SUB]\", par)) + len(re.findall(r\"\\[RM]\", par))\n",
    "        editions.append(num_editions)\n",
    "    sum_editions.append(np.sum(editions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690d462-bd3e-4ecb-8a3d-4cc0aae82e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_editions.index(7)\n",
    "sum_editions.index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "7a8da3ca-f1e5-4e72-a8bf-db16a4cbcd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum_editions.index(7) # 54 # max\n",
    "# sum_edtitions.index(2) # 0 # mean\n",
    "# sum_editions.index(0) # 2 # min\n",
    "# find the no.54 from short_idx (find the global idx)\n",
    "# find the no.0 from short_idx (find the global idx)\n",
    "# find the no. from short_idx (find the global idx)\n",
    "# short_idx[54] # return 115 # max\n",
    "# short_idx[0] # return 1 # mean\n",
    "short_idx[2] # return 9 # min\n",
    "# so, we apply the max editions mode for FSL with index 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "5f74b90c-8a0e-44ce-8411-a1c695e59cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "min_few_shots_prompt = f\"\"\"\n",
    "Here's the example of OLD version, the news information, and the updated version.\\n\n",
    "OLD VERSION:\\n\n",
    "{olds[idx]}\n",
    "\\nNEW INFORMATION:\\n\n",
    "{triggers[idx]}\n",
    "\\nUPDATED VERSION:\\n\n",
    "{news[idx]}\n",
    "\\n\\n Later, I will provides more instances for you, and you have to give me the updated version of articles. Can you do that?\\n\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "e1f09d13-cef6-4705-b8d2-c3d200594f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I can do that. Please provide me with more instances.'"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = []\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": min_few_shots_prompt}\n",
    "    ]\n",
    ")\n",
    "response = completion.choices[0].message.content\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "2aacb427-4f4b-4ddf-a416-5770e0411f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for idx in range(len(olds)):\n",
    "    single_input = f\"\"\"\n",
    "Here's the OLD VERSION, the NEW INFORMATION, and you have to return the UPDATED VERSION of article.\\n\n",
    "OLD VERSION:\\n\n",
    "{olds[idx]}\n",
    "\\nNEW INFORMATION:\\n\n",
    "{triggers[idx]}\n",
    "\"\"\"\n",
    "    inputs.append(single_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f6b853a6-c415-4140-9058-af2d713a7679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3849 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the input length with shorter than 4096\n",
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "short_idx = []\n",
    "for idx in range(len(inputs)):\n",
    "    input_len = len(tokenizer(inputs[idx])[\"input_ids\"])\n",
    "    if input_len < 3900:\n",
    "        short_idx.append(idx)\n",
    "len(short_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "9cdd6997-44c5-4413-98b0-b83b8058a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_confirmed = []\n",
    "for idx in short_idx:\n",
    "    single_input = f\"\"\"\n",
    "Here's the OLD VERSION, the NEW INFORMATION, and you have to return the UPDATED VERSION of article.\\n\n",
    "OLD VERSION:\\n\n",
    "{olds[idx]}\n",
    "\\nNEW INFORMATION:\\n\n",
    "{triggers[idx]}\n",
    "\"\"\"\n",
    "    inputs_confirmed.append(single_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "6f9f9278-bae3-4bc7-a4fa-7229b1426d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for input_confirmed in inputs_confirmed:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": input_confirmed}\n",
    "        ]\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "97a2edb2-937c-4a10-9937-fb9f0c31757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"idx\": short_idx, \"response\": responses}).to_csv(\"./chatgpt-fewshots/chatgpt_min_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "6407f40f-d18c-43a9-ae90-0942838682bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_check = []\n",
    "with open(\"../same_secs_insert/test_text.txt.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        refs_check.append(line.strip())\n",
    "len(refs_check)\n",
    "with open(\"./chatgpt-fewshots/chatgpt_min_2.ref.txt\", \"w\") as f:\n",
    "    for idx in short_idx:\n",
    "        f.write(refs_check[idx]+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-venv",
   "language": "python",
   "name": "data-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
